# Copyright (C) 2025 Holaf
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

import torch
import folder_paths
import comfy.model_management
import comfy.utils
from spandrel import ModelLoader
from nodes import ImageScale

class UpscaleImageHolaf:
    """
    Upscales an image using a chosen model (e.g., ESRGAN) to a target
    megapixel count. This provides flexible size control, independent of the
    model's native scale factor (e.g., 4x).
    Now supports enforcing resolution multiples (8, 16) and fitting strategies (Stretch, Crop, Pad).
    """
    upscale_methods = ["nearest-exact", "bilinear", "area", "bicubic", "lanczos"]
    multiples = ["None", "8", "16"]
    resize_modes = ["stretch", "crop", "pad"]

    @classmethod
    def INPUT_TYPES(s):
        # Dynamically populates the `model_name` dropdown with files from the `upscale_models` folder.
        try:
            upscale_model_list = folder_paths.get_filename_list("upscale_models")
            if not upscale_model_list:
                upscale_model_list = ["None"]
        except Exception:
            upscale_model_list = ["None"]
            print("Warning: Could not access upscale_models folder.")

        return {
            "required": {
                "image": ("IMAGE",),
                "model_name": (upscale_model_list, ),
                "upscale_method": (s.upscale_methods,),
                # The target output size, expressed in megapixels.
                "megapixels": ("FLOAT", {"default": 2.00, "min": 0.01, "max": 16.00, "step": 0.01}),
                "force_multiple_of": (s.multiples, {"default": "None"}),
                "resize_mode": (s.resize_modes, {"default": "stretch"}),
                "clean_vram": ("BOOLEAN", {"default": False}),
            }
        }

    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("IMAGE", "MODEL_NAME_TEXT")
    FUNCTION = "upscale"
    CATEGORY = "Holaf"

    def upscale(self, image, model_name, upscale_method, megapixels, force_multiple_of, resize_mode, clean_vram):
        # Optionally clear VRAM to free up memory before the main operation.
        if clean_vram:
            comfy.model_management.soft_empty_cache()

        # If no model is selected, simply pass the image through without changes.
        if model_name == "None" or not model_name:
             return (image, "None")

        # --- Model Loading ---
        # Load the selected upscale model. Spandrel is used here for its broad
        # compatibility with various upscaler model architectures.
        model_path = folder_paths.get_full_path("upscale_models", model_name)
        if not model_path:
            raise FileNotFoundError(f"Upscale model not found: {model_name}")

        device = comfy.model_management.get_torch_device()
        try:
            sd = comfy.utils.load_torch_file(model_path, safe_load=True)
            upscale_model_descriptor = ModelLoader().load_from_state_dict(sd)
            upscale_model = upscale_model_descriptor.model
            upscale_model.eval()
        except Exception as e:
            raise RuntimeError(f"Failed to load upscale model '{model_name}': {e}") from e

        # --- Target Dimension Calculation ---
        # Calculate the target width and height to match the desired megapixel count
        # while preserving the original aspect ratio.
        _, original_height, original_width, _ = image.shape
        original_pixels = original_height * original_width
        target_pixels = megapixels * 1048576.0 # 1 MP = 1024*1024 pixels

        if target_pixels <= 0: raise ValueError("Megapixels must be positive.")
        if original_pixels <= 0: return (image, model_name)

        # The scale factor is the square root of the ratio of target pixels to original pixels.
        scale_factor = (target_pixels / original_pixels) ** 0.5
        target_width = max(1, int(original_width * scale_factor))
        target_height = max(1, int(original_height * scale_factor))

        # --- Apply Modulo Constraint ---
        if force_multiple_of != "None":
            multiple = int(force_multiple_of)
            target_width = round(target_width / multiple) * multiple
            target_height = round(target_height / multiple) * multiple
            target_width = max(multiple, target_width)
            target_height = max(multiple, target_height)

        # --- Two-Stage Upscaling ---
        # FIX: Explicitly cast the input tensor to float32 (torch.float) to prevent type mismatch errors.
        image = image.float()

        # Stage 1: Upscale using the loaded model's native scale factor.
        image_for_model = image.movedim(-1, 1) # Permute to NCHW for model input
        try:
            with torch.no_grad():
                 upscale_model.to(device)
                 model_scale = upscale_model_descriptor.scale
                 scaled_img = comfy.utils.tiled_scale(
                      image_for_model,
                      lambda x: upscale_model(x.to(device)).cpu(),
                      tile_x=512, tile_y=512, overlap=64,
                      upscale_amount=model_scale
                 )
        except Exception as e:
             raise RuntimeError(f"Failed to upscale image with model '{model_name}': {e}") from e

        upscaled_image = scaled_img.movedim(1, -1) # Permute back to NHWC

        # Stage 2: Final Resize with Mode (Stretch/Crop/Pad)
        current_height, current_width = upscaled_image.shape[1:3]

        if current_width != target_width or current_height != target_height:
             resizer = ImageScale()

             if resize_mode == "stretch":
                 # Direct resize to target dimensions (ignoring aspect ratio changes)
                 upscaled_image = resizer.upscale(upscaled_image, upscale_method, target_width, target_height, "disabled")[0]

             elif resize_mode == "crop":
                 # Scale to cover target, then crop center
                 scale_w = target_width / current_width
                 scale_h = target_height / current_height
                 scale = max(scale_w, scale_h)

                 temp_w = int(current_width * scale)
                 temp_h = int(current_height * scale)

                 # Upscale first
                 upscaled_image = resizer.upscale(upscaled_image, upscale_method, temp_w, temp_h, "disabled")[0]

                 # Then crop
                 x_start = (temp_w - target_width) // 2
                 y_start = (temp_h - target_height) // 2
                 upscaled_image = upscaled_image[:, y_start:y_start+target_height, x_start:x_start+target_width, :]

             elif resize_mode == "pad":
                 # Scale to fit inside target, then pad with black
                 scale_w = target_width / current_width
                 scale_h = target_height / current_height
                 scale = min(scale_w, scale_h)

                 temp_w = int(current_width * scale)
                 temp_h = int(current_height * scale)

                 # Upscale first
                 upscaled_image = resizer.upscale(upscaled_image, upscale_method, temp_w, temp_h, "disabled")[0]

                 # Then pad
                 new_image = torch.zeros((upscaled_image.shape[0], target_height, target_width, upscaled_image.shape[3]), dtype=upscaled_image.dtype, device=upscaled_image.device)
                 x_start = (target_width - temp_w) // 2
                 y_start = (target_height - temp_h) // 2
                 new_image[:, y_start:y_start+temp_h, x_start:x_start+temp_w, :] = upscaled_image
                 upscaled_image = new_image

        return (upscaled_image, model_name)